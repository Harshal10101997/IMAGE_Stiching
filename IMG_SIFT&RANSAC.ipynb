{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "figsize = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_l = cv2.cvtColor(cv2.imread(read_image), cv2.COLOR_BGR2RGB)\n",
    "gray_l = cv2.cvtColor(rgb_l, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(gray_l)\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "rgb_r = cv2.cvtColor(cv2.imread(read_image), cv2.COLOR_BGR2RGB)\n",
    "gray_r = cv2.cvtColor(rgb_r, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(gray_r)\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#harris corner detector\n",
    "from pylab import *\n",
    "from scipy import signal\n",
    "from scipy import *\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def gauss_derivative_kernels(size, sizey=None):\n",
    "    \"\"\" returns x and y derivatives of a 2D \n",
    "        gauss kernel array for convolutions \"\"\"\n",
    "    size = int(size)\n",
    "    if not sizey:\n",
    "        sizey = size\n",
    "    else:\n",
    "        sizey = int(sizey)\n",
    "    y, x = mgrid[-size:size+1, -sizey:sizey+1]\n",
    "    #x and y derivatives of a 2D gaussian with standard dev half of size\n",
    "\n",
    "    gx = - x * exp(-(x**2/float((0.5*size)**2)+y**2/float((0.5*sizey)**2))) \n",
    "    gy = - y * exp(-(x**2/float((0.5*size)**2)+y**2/float((0.5*sizey)**2))) \n",
    "    return gx,gy\n",
    "\n",
    "def gauss_kernel(size, sizey = None):\n",
    "    \"\"\" Returns a normalized 2D gauss kernel array for convolutions \"\"\"\n",
    "    size = int(size)\n",
    "    if not sizey:\n",
    "        sizey = size\n",
    "    else:\n",
    "        sizey = int(sizey)\n",
    "    x, y = mgrid[-size:size+1, -sizey:sizey+1]\n",
    "    g = exp(-(x**2/float(size)+y**2/float(sizey)))\n",
    "    return g / g.sum()\n",
    "\n",
    "def compute_harris_response(im):\n",
    "    \"\"\" compute the Harris corner detector response function \n",
    "        for each pixel in the image\"\"\"\n",
    "    #derivatives\n",
    "    gx,gy = gauss_derivative_kernels(3)\n",
    "    imx = signal.convolve(im,gx, mode='same')\n",
    "    imy = signal.convolve(im,gy, mode='same')\n",
    "    #kernel for blurring\n",
    "    gauss = gauss_kernel(3)\n",
    "    #compute components of the structure tensor\n",
    "    Wxx = signal.convolve(imx*imx,gauss, mode='same')\n",
    "    Wxy = signal.convolve(imx*imy,gauss, mode='same')\n",
    "    Wyy = signal.convolve(imy*imy,gauss, mode='same')   \n",
    "    #determinant and trace\n",
    "    Wdet = Wxx*Wyy - Wxy**2\n",
    "    Wtr = Wxx + Wyy   \n",
    "    return Wdet / Wtr\n",
    "\n",
    "def get_harris_points(harrisim, min_distance=10, threshold=0.1):\n",
    "    \"\"\" return corners from a Harris response image\n",
    "        min_distance is the minimum nbr of pixels separating \n",
    "        corners and image boundary\"\"\"\n",
    "    #find top corner candidates above a threshold\n",
    "    corner_threshold = max(harrisim.ravel()) * threshold\n",
    "    harrisim_t = (harrisim > corner_threshold) * 1    \n",
    "    #get coordinates of candidates\n",
    "    candidates = harrisim_t.nonzero()\n",
    "    coords = [ (candidates[0][c],candidates[1][c]) for c in range(len(candidates[0]))]\n",
    "    #...and their values\n",
    "    candidate_values = [harrisim[c[0]][c[1]] for c in coords]    \n",
    "    #sort candidates\n",
    "    index = argsort(candidate_values)   \n",
    "    #store allowed point locations in array\n",
    "    allowed_locations = zeros(harrisim.shape)\n",
    "    allowed_locations[min_distance:-min_distance,min_distance:-min_distance] = 1   \n",
    "    #select the best points taking min_distance into account\n",
    "    filtered_coords = []\n",
    "    for i in index:\n",
    "        if allowed_locations[coords[i][0]][coords[i][1]] == 1:\n",
    "            filtered_coords.append(coords[i])\n",
    "            allowed_locations[(coords[i][0]-min_distance):(coords[i][0]+min_distance),\n",
    "                (coords[i][1]-min_distance):(coords[i][1]+min_distance)] = 0               \n",
    "    return filtered_coords\n",
    "\n",
    "def plot_harris_points(image, filtered_coords):\n",
    "    \"\"\" plots corners found in image\"\"\"\n",
    "    figure()\n",
    "    gray()\n",
    "    imshow(image)\n",
    "    plot([p[1] for p in filtered_coords],[p[0] for p in filtered_coords],'r*')\n",
    "    axis('off')\n",
    "    show()\n",
    "\n",
    "def harris(filename, min_distance = 10, threshold = 0.1):\n",
    "    \"\"\"\n",
    "    filename: Path of image file\n",
    "    threshold: (optional)Threshold for corner detection\n",
    "    min_distance : (optional)Minimum number of pixels separating \n",
    "     corners and image boundary\n",
    "    \"\"\"\n",
    "    im = np.array(Image.open(filename).convert(\"L\"))\n",
    "    harrisim = compute_harris_response(im)\n",
    "    filtered_coords = get_harris_points(harrisim,min_distance, threshold)\n",
    "    plot_harris_points(im, filtered_coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_1 = (Read_image)\n",
    "harris(Image_1)\n",
    "Image_2 = (Read_image)\n",
    "harris(Image_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SIFT feature detection and description\n",
    "\n",
    "feature_extractor = cv2.SIFT_create()\n",
    "\n",
    "# find the keypoints and descriptors with chosen feature_extractor\n",
    "kp_l, desc_l = feature_extractor.detectAndCompute(gray_l, None)\n",
    "kp_r, desc_r = feature_extractor.detectAndCompute(gray_r, None)\n",
    "\n",
    "test = cv2.drawKeypoints(rgb_l, kp_l, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(test)\n",
    "plt.title(\"SIFT Descriptor\")\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## take only unique feature\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(desc_l, desc_r, k=2)\n",
    "\n",
    "# Apply ratio test\n",
    "good_match = []\n",
    "for m in matches:\n",
    "    if m[0].distance/m[1].distance < 0.5:\n",
    "        good_match.append(m)\n",
    "good_match_arr = np.asarray(good_match)\n",
    "\n",
    "# show only 30 matches\n",
    "im_matches = cv2.drawMatchesKnn(rgb_l, kp_l, rgb_r, kp_r,\n",
    "                                good_match[0:30], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(im_matches)\n",
    "plt.title(\"Matching  keypoints\")\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##find homography between images\n",
    "\n",
    "good_kp_l = np.array([kp_l[m.queryIdx].pt for m in good_match_arr[:, 0]]).reshape(-1, 1, 2)\n",
    "good_kp_r = np.array([kp_r[m.trainIdx].pt for m in good_match_arr[:, 0]]).reshape(-1, 1, 2)\n",
    "H, masked = cv2.findHomography(good_kp_r, good_kp_l, cv2.RANSAC, 5.0)    # Rnsac used here\n",
    "\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_r_warped = cv2.warpPerspective(rgb_r, H, (rgb_l.shape[1] + rgb_r.shape[1], rgb_l.shape[0]))\n",
    "rgb_r_warped[0:rgb_l.shape[0], 0:rgb_l.shape[1]] = rgb_l\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(rgb_r_warped)\n",
    "plt.title(\"Inliner Matching\")\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpTwoImages(img1, img2, H):\n",
    "    '''warp img2 to img1 with homograph H '''\n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "    pts1 = np.float32([[0, 0], [0, h1], [w1, h1], [w1, 0]]).reshape(-1, 1, 2)\n",
    "    pts2 = np.float32([[0, 0], [0, h2], [w2, h2], [w2, 0]]).reshape(-1, 1, 2)\n",
    "    pts2_ = cv2.perspectiveTransform(pts2, H)\n",
    "    pts = np.concatenate((pts1, pts2_), axis=0)\n",
    "    [xmin, ymin] = np.int32(pts.min(axis=0).ravel() - 0.5)\n",
    "    [xmax, ymax] = np.int32(pts.max(axis=0).ravel() + 0.5)\n",
    "    t = [-xmin, -ymin]\n",
    "    Ht = np.array([[1, 0, t[0]], [0, 1, t[1]], [0, 0, 1]])  # translate\n",
    "\n",
    "    result = cv2.warpPerspective(img2, Ht@H, (xmax-xmin, ymax-ymin))\n",
    "    result[t[1]:h1+t[1], t[0]:w1+t[0]] = img1\n",
    "    return result\n",
    "\n",
    "\n",
    "result = warpTwoImages(rgb_l, rgb_r, H)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(result)\n",
    "plt.title(\"Panoramic Image\")\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
